"""
Multi-Platform Course Scraper - VERSI√ìN MEJORADA
Scraper profesional para Coursera, edX y otras plataformas
CON VERIFICACI√ìN REAL Y ROBUSTA DE DATOS DE CADA CURSO
"""
"""
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from db.connection import get_connection
from datetime import datetime
import time
import random
import requests
from bs4 import BeautifulSoup
import json
import re
import logging
from urllib.parse import quote, urljoin

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class MultiPlatformScraper:
    def __init__(self):
        self.session = requests.Session()
        self.setup_session()
        
    def setup_session(self):
        """Configura la sesi√≥n HTTP"""
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'es-ES,es;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
        }
        self.session.headers.update(headers)

    def create_driver(self):
        """Crea driver b√°sico para casos que necesiten JavaScript"""
        options = Options()
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--window-size=1920,1080')
        
        try:
            return webdriver.Chrome(options=options)
        except Exception as e:
            logger.error(f"Error creando driver: {e}")
            return None

    def clean_description(self, text):
        """Limpia y formatea la descripci√≥n"""
        if not text:
            return ""
        
        # Remover caracteres especiales y normalizar espacios
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'[^\w\s\.,!?;:()\-√°√©√≠√≥√∫√±√º]', '', text, flags=re.IGNORECASE)
        text = text.strip()
        
        # Limitar longitud pero mantener palabras completas
        if len(text) > 800:
            text = text[:800]
            last_space = text.rfind(' ')
            if last_space > 600:
                text = text[:last_space] + "..."
        
        return text

    # ================== VERIFICACI√ìN MEJORADA DE DETALLES DE CURSOS ==================
    
    def get_coursera_course_details(self, url):
        """Obtiene detalles reales MEJORADOS de un curso de Coursera"""
        try:
            logger.info(f"üîç Verificando detalles de Coursera: {url}")
            response = self.session.get(url, timeout=25)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                
                details = {
                    'descripcion': '',
                    'certificado': 0,
                    'tipo': 'gratis'
                }
                
                # ===== DESCRIPCI√ìN - SELECTORES AMPLIADOS =====
                desc_selectors = [
                    # Selectores principales de Coursera
                    'div[data-testid="course-about"]',
                    'div[data-testid="description"]',
                    '.course-description',
                    '.about-section p',
                    '.rc-CML',  # Coursera markup language
                    '.description-content',
                    '.course-intro',
                    '.overview-content',
                    'div[class*="description"]',
                    'div[class*="about"]',
                    'div[class*="overview"]',
                    # Meta tags como fallback
                    'meta[name="description"]',
                    'meta[property="og:description"]',
                    'meta[name="twitter:description"]'
                ]
                
                description_found = False
                for selector in desc_selectors:
                    try:
                        if selector.startswith('meta'):
                            elem = soup.select_one(selector)
                            if elem and elem.get('content'):
                                content = elem.get('content', '').strip()
                                if len(content) > 50:  # M√≠nimo 50 caracteres para ser √∫til
                                    details['descripcion'] = self.clean_description(content)
                                    description_found = True
                                    break
                        else:
                            elems = soup.select(selector)
                            if elems:
                                # Tomar el elemento con m√°s contenido
                                best_elem = max(elems, key=lambda x: len(x.get_text().strip()))
                                content = best_elem.get_text().strip()
                                if len(content) > 50:
                                    details['descripcion'] = self.clean_description(content)
                                    description_found = True
                                    break
                    except Exception as e:
                        continue
                
                # Si no encontramos descripci√≥n, intentar con p√°rrafos generales
                if not description_found:
                    paragraphs = soup.select('p')
                    best_paragraph = ""
                    for p in paragraphs:
                        text = p.get_text().strip()
                        if len(text) > len(best_paragraph) and len(text) > 100:
                            # Verificar que no sea navegaci√≥n o footer
                            if not any(skip in text.lower() for skip in ['cookie', 'policy', 'terms', 'navigation', 'menu']):
                                best_paragraph = text
                    
                    if best_paragraph:
                        details['descripcion'] = self.clean_description(best_paragraph)
                
                # ===== VERIFICACI√ìN DE TIPO (GRATIS/PAGO/FREEMIUM) =====
                page_text = soup.get_text().lower()
                
                # Indicadores de contenido gratuito
                free_indicators = [
                    'free course', 'curso gratuito', 'audit for free', 'free to audit',
                    'enroll for free', 'free enrollment', 'gratuito',
                    'financial aid available', 'scholarships available',
                    'free access', 'no cost'
                ]
                
                # Indicadores de contenido de pago
                paid_indicators = [
                    r'\$\d+', r'\d+\s*usd', 'subscription required', 'plus subscription',
                    'premium', 'certificate fee', 'paid course', 'curso de pago',
                    'monthly subscription', 'annual subscription', 'coursera plus',
                    'payment required', 'upgrade to'
                ]
                
                # Indicadores de freemium (gratis con opciones de pago)
                freemium_indicators = [
                    'free with certificate option', 'free audit', 'certificate available for purchase',
                    'graded assignments require payment', 'certificate requires payment'
                ]
                
                # L√≥gica de detecci√≥n mejorada
                is_free = any(indicator in page_text for indicator in free_indicators)
                is_paid = any(re.search(indicator, page_text) for indicator in paid_indicators)
                is_freemium = any(indicator in page_text for indicator in freemium_indicators)
                
                if is_freemium or (is_free and is_paid):
                    details['tipo'] = 'freemium'
                elif is_paid and not is_free:
                    details['tipo'] = 'pago'
                else:
                    details['tipo'] = 'gratis'
                
                # ===== VERIFICACI√ìN DE CERTIFICADO =====
                cert_indicators = [
                    'shareable certificate', 'certificado compartible',
                    'professional certificate', 'certificado profesional',
                    'course certificate', 'certificado del curso',
                    'certificate upon completion', 'certificate included',
                    'verified certificate', 'certificado verificado',
                    'certificate available', 'earn a certificate'
                ]
                
                has_certificate = any(indicator in page_text for indicator in cert_indicators)
                
                # Verificaci√≥n adicional en elementos espec√≠ficos
                if not has_certificate:
                    cert_elements = soup.select('[class*="certificate"]') + soup.select('[data-testid*="certificate"]')
                    has_certificate = len(cert_elements) > 0
                
                details['certificado'] = 1 if has_certificate else 0
                
                logger.info(f"‚úÖ Coursera - Descripci√≥n: {len(details['descripcion'])} chars, Tipo: {details['tipo']}, Certificado: {'S√≠' if details['certificado'] else 'No'}")
                return details
                
        except Exception as e:
            logger.error(f"Error obteniendo detalles de Coursera: {e}")
            
        return {'descripcion': '', 'certificado': 0, 'tipo': 'gratis'}
    
    def get_edx_course_details(self, url):
        """Obtiene detalles reales MEJORADOS de un curso de edX"""
        try:
            logger.info(f"üîç Verificando detalles de edX: {url}")
            response = self.session.get(url, timeout=25)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                
                details = {
                    'descripcion': '',
                    'certificado': 0,
                    'tipo': 'gratis'
                }
                
                # ===== DESCRIPCI√ìN - SELECTORES ESPEC√çFICOS EDX =====
                desc_selectors = [
                    '.course-intro-lead-in',
                    '.course-description',
                    '[data-testid="course-description"]',
                    '.about-content p',
                    '.course-about',
                    '.course-overview',
                    '.course-info-content',
                    'div[class*="description"]',
                    'section[class*="about"]',
                    'meta[property="og:description"]',
                    'meta[name="description"]'
                ]
                
                for selector in desc_selectors:
                    try:
                        if selector.startswith('meta'):
                            elem = soup.select_one(selector)
                            if elem and elem.get('content'):
                                content = elem.get('content', '').strip()
                                if len(content) > 50:
                                    details['descripcion'] = self.clean_description(content)
                                    break
                        else:
                            elems = soup.select(selector)
                            if elems:
                                best_elem = max(elems, key=lambda x: len(x.get_text().strip()))
                                content = best_elem.get_text().strip()
                                if len(content) > 50:
                                    details['descripcion'] = self.clean_description(content)
                                    break
                    except Exception:
                        continue
                
                page_text = soup.get_text().lower()
                
                # ===== VERIFICACI√ìN DE TIPO EDX =====
                # edX tiene un modelo espec√≠fico: audit (gratis) vs verified (pago)
                if any(indicator in page_text for indicator in ['audit track', 'audit for free', 'free audit']):
                    details['tipo'] = 'freemium'  # Gratis con opci√≥n de pago
                elif any(indicator in page_text for indicator in ['verified track', 'verified certificate', 'upgrade']):
                    if 'free' in page_text or 'audit' in page_text:
                        details['tipo'] = 'freemium'
                    else:
                        details['tipo'] = 'pago'
                elif any(indicator in page_text for indicator in ['$', 'usd', 'payment']):
                    details['tipo'] = 'pago'
                else:
                    details['tipo'] = 'gratis'
                
                # ===== VERIFICACI√ìN DE CERTIFICADO EDX =====
                cert_indicators = [
                    'verified certificate', 'certificate of completion',
                    'professional certificate', 'micromasters certificate',
                    'certificate track', 'earn a certificate'
                ]
                
                details['certificado'] = 1 if any(indicator in page_text for indicator in cert_indicators) else 0
                
                logger.info(f"‚úÖ edX - Descripci√≥n: {len(details['descripcion'])} chars, Tipo: {details['tipo']}, Certificado: {'S√≠' if details['certificado'] else 'No'}")
                return details
                
        except Exception as e:
            logger.error(f"Error obteniendo detalles de edX: {e}")
            
        return {'descripcion': '', 'certificado': 0, 'tipo': 'gratis'}
    
    def get_khan_academy_details(self, url):
        """Obtiene detalles MEJORADOS de Khan Academy"""
        try:
            logger.info(f"üîç Verificando detalles de Khan Academy: {url}")
            response = self.session.get(url, timeout=20)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                
                details = {
                    'descripcion': '',
                    'certificado': 0,  # Khan Academy no da certificados formales
                    'tipo': 'gratis'   # Todo es gratis en Khan Academy
                }
                
                # ===== DESCRIPCI√ìN KHAN ACADEMY =====
                desc_selectors = [
                    '.course-description',
                    '.intro-text',
                    '.description',
                    '.course-intro',
                    'div[class*="description"]',
                    'p[class*="intro"]',
                    'meta[name="description"]',
                    'meta[property="og:description"]'
                ]
                
                # Intentar encontrar una descripci√≥n significativa
                for selector in desc_selectors:
                    try:
                        if selector.startswith('meta'):
                            elem = soup.select_one(selector)
                            if elem and elem.get('content'):
                                content = elem.get('content', '').strip()
                                if len(content) > 30:
                                    details['descripcion'] = self.clean_description(content)
                                    break
                        else:
                            elems = soup.select(selector)
                            for elem in elems:
                                content = elem.get_text().strip()
                                if len(content) > 50:
                                    details['descripcion'] = self.clean_description(content)
                                    break
                            if details['descripcion']:
                                break
                    except Exception:
                        continue
                
                # Si no encontramos descripci√≥n espec√≠fica, buscar en p√°rrafos
                if not details['descripcion']:
                    paragraphs = soup.select('p')
                    for p in paragraphs:
                        text = p.get_text().strip()
                        if len(text) > 80 and not any(skip in text.lower() for skip in ['cookie', 'policy', 'login']):
                            details['descripcion'] = self.clean_description(text)
                            break
                
                # Si a√∫n no hay descripci√≥n, crear una basada en el t√≠tulo/contenido
                if not details['descripcion']:
                    title = soup.select_one('title')
                    if title:
                        title_text = title.get_text().strip()
                        details['descripcion'] = f"Curso gratuito de Khan Academy: {title_text}"
                
                logger.info(f"‚úÖ Khan Academy - Descripci√≥n: {len(details['descripcion'])} chars")
                return details
                
        except Exception as e:
            logger.error(f"Error obteniendo detalles de Khan Academy: {e}")
            
        return {'descripcion': 'Curso gratuito de Khan Academy para aprender de forma interactiva', 'certificado': 0, 'tipo': 'gratis'}
    
    def get_freecodecamp_details(self, url):
        """Obtiene detalles MEJORADOS de freeCodeCamp"""
        try:
            logger.info(f"üîç Verificando detalles de freeCodeCamp: {url}")
            response = self.session.get(url, timeout=20)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                
                details = {
                    'descripcion': '',
                    'certificado': 1,  # freeCodeCamp da certificados
                    'tipo': 'gratis'   # Todo es gratis
                }
                
                # ===== DESCRIPCI√ìN FREECODECAMP =====
                desc_selectors = [
                    '.course-description',
                    '.intro-description',
                    '.learn-description p',
                    '.certification-description',
                    'div[class*="description"]',
                    '.course-intro',
                    'meta[name="description"]',
                    'meta[property="og:description"]'
                ]
                
                for selector in desc_selectors:
                    try:
                        if selector.startswith('meta'):
                            elem = soup.select_one(selector)
                            if elem and elem.get('content'):
                                content = elem.get('content', '').strip()
                                if len(content) > 40:
                                    details['descripcion'] = self.clean_description(content)
                                    break
                        else:
                            elems = soup.select(selector)
                            if elems:
                                best_elem = max(elems, key=lambda x: len(x.get_text().strip()))
                                content = best_elem.get_text().strip()
                                if len(content) > 50:
                                    details['descripcion'] = self.clean_description(content)
                                    break
                    except Exception:
                        continue
                
                # Verificar si realmente da certificado buscando en el contenido
                page_text = soup.get_text().lower()
                cert_keywords = ['certificate', 'certificado', 'certification', 'earn certificate']
                details['certificado'] = 1 if any(keyword in page_text for keyword in cert_keywords) else 0
                
                logger.info(f"‚úÖ freeCodeCamp - Descripci√≥n: {len(details['descripcion'])} chars, Certificado: {'S√≠' if details['certificado'] else 'No'}")
                return details
                
        except Exception as e:
            logger.error(f"Error obteniendo detalles de freeCodeCamp: {e}")
            
        return {'descripcion': 'Curso gratuito de programaci√≥n con certificado al completar el curr√≠culum', 'certificado': 1, 'tipo': 'gratis'}

    # ================== COURSERA SCRAPER (CON VERIFICACI√ìN MEJORADA) ==================
    def search_coursera(self, query):
        """Scraper para Coursera con verificaci√≥n mejorada"""
        logger.info(f"üéì Buscando en Coursera: {query}")
        courses = []
        
        try:
            search_url = f"https://www.coursera.org/search?query={quote(query)}&"
            response = self.session.get(search_url, timeout=15)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                
                course_selectors = [
                    'div[data-testid="search-filter-group-results"] div[data-testid="search-result-card"]',
                    'div.result-title-container',
                    'div[class*="SearchResult"]',
                    'a[href*="/learn/"]'
                ]
                
                for selector in course_selectors:
                    course_cards = soup.select(selector)
                    if course_cards:
                        logger.info(f"‚úÖ Coursera: Encontrados {len(course_cards)} cursos")
                        
                        for i, card in enumerate(course_cards[:8]):  # Limitamos para mejores detalles
                            course = self.parse_coursera_course(card)
                            if course:
                                logger.info(f"   üîç Verificando curso {i+1}/{min(8, len(course_cards))}: {course['titulo'][:40]}...")
                                
                                # OBTENER DETALLES REALES MEJORADOS
                                time.sleep(random.uniform(2, 4))
                                details = self.get_coursera_course_details(course['url'])
                                
                                # Solo agregar si tenemos una descripci√≥n v√°lida
                                if details['descripcion'] and len(details['descripcion']) > 20:
                                    course.update(details)
                                    course['plataforma'] = 'Coursera'
                                    courses.append(course)
                                    logger.info(f"   ‚úÖ Agregado: {details['tipo']} - Cert: {'S√≠' if details['certificado'] else 'No'}")
                                else:
                                    logger.warning(f"   ‚ö†Ô∏è Descripci√≥n insuficiente, omitiendo curso")
                        break
                        
        except Exception as e:
            logger.error(f"‚ùå Error en Coursera: {e}")
        
        logger.info(f"üìä Coursera: {len(courses)} cursos procesados con detalles verificados")
        return courses

    def parse_coursera_course(self, card):
        """Parsea un curso de Coursera"""
        try:
            course = {
                'titulo': '',
                'url': '',
                'disponible': 1
            }
            
            # T√≠tulo
            title_selectors = ['h3', 'h2', '.result-title', '[data-testid="search-result-title"]']
            for selector in title_selectors:
                title_elem = card.select_one(selector)
                if title_elem:
                    course['titulo'] = title_elem.get_text().strip()
                    break
            
            # URL
            link = card.select_one('a[href*="/learn/"]') or card.select_one('a')
            if link:
                href = link.get('href')
                course['url'] = urljoin('https://www.coursera.org', href)
            
            return course if course['titulo'] and course['url'] else None
            
        except Exception as e:
            return None

    # ================== EDX SCRAPER (CON VERIFICACI√ìN MEJORADA) ==================
    def search_edx(self, query):
        """Scraper para edX con verificaci√≥n mejorada"""
        logger.info(f"üè´ Buscando en edX: {query}")
        courses = []
        
        try:
            search_url = f"https://www.edx.org/search?q={quote(query)}"
            response = self.session.get(search_url, timeout=15)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                
                course_selectors = [
                    'div[data-testid="course-card"]',
                    '.course-card',
                    'div[class*="CourseCard"]',
                    'a[href*="/course/"]'
                ]
                
                for selector in course_selectors:
                    course_cards = soup.select(selector)
                    if course_cards:
                        logger.info(f"‚úÖ edX: Encontrados {len(course_cards)} cursos")
                        
                        for i, card in enumerate(course_cards[:8]):
                            course = self.parse_edx_course(card)
                            if course:
                                logger.info(f"   üîç Verificando curso {i+1}/{min(8, len(course_cards))}: {course['titulo'][:40]}...")
                                
                                # OBTENER DETALLES REALES MEJORADOS
                                time.sleep(random.uniform(2, 4))
                                details = self.get_edx_course_details(course['url'])
                                
                                # Solo agregar si tenemos descripci√≥n v√°lida
                                if details['descripcion'] and len(details['descripcion']) > 20:
                                    course.update(details)
                                    course['plataforma'] = 'edX'
                                    courses.append(course)
                                    logger.info(f"   ‚úÖ Agregado: {details['tipo']} - Cert: {'S√≠' if details['certificado'] else 'No'}")
                                else:
                                    logger.warning(f"   ‚ö†Ô∏è Descripci√≥n insuficiente, omitiendo curso")
                        break
                        
        except Exception as e:
            logger.error(f"‚ùå Error en edX: {e}")
        
        logger.info(f"üìä edX: {len(courses)} cursos procesados con detalles verificados")
        return courses

    def parse_edx_course(self, card):
        """Parsea un curso de edX"""
        try:
            course = {
                'titulo': '',
                'url': '',
                'disponible': 1
            }
            
            # T√≠tulo
            title_elem = card.select_one('h3') or card.select_one('h2') or card.select_one('.title')
            if title_elem:
                course['titulo'] = title_elem.get_text().strip()
            
            # URL
            link = card.select_one('a[href*="/course/"]') or card.select_one('a')
            if link:
                href = link.get('href')
                course['url'] = urljoin('https://www.edx.org', href)
            
            return course if course['titulo'] and course['url'] else None
            
        except Exception as e:
            return None

    # ================== KHAN ACADEMY SCRAPER (CON VERIFICACI√ìN MEJORADA) ==================
    def search_khan_academy(self, query):
        """Scraper para Khan Academy con verificaci√≥n mejorada"""
        logger.info(f"üìö Buscando en Khan Academy: {query}")
        courses = []
        
        try:
            search_url = f"https://www.khanacademy.org/search?page_search_query={quote(query)}"
            response = self.session.get(search_url, timeout=15)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                links = soup.select('a[href*="/"]')
                
                processed = 0
                for link in links:
                    if processed >= 6:  # Limitamos para mejor calidad
                        break
                        
                    href = link.get('href', '')
                    title = link.get_text().strip()
                    
                    if (title and len(title) > 10 and 
                        any(keyword in href.lower() for keyword in ['math', 'science', 'computing', 'economics', 'arts']) and
                        not any(skip in href.lower() for skip in ['javascript:', '#', 'mailto:', 'tel:'])):
                        
                        course_url = urljoin('https://www.khanacademy.org', href)
                        logger.info(f"   üîç Verificando: {title[:40]}...")
                        
                        # OBTENER DETALLES REALES MEJORADOS
                        time.sleep(random.uniform(1, 3))
                        details = self.get_khan_academy_details(course_url)
                        
                        # Solo agregar si tenemos descripci√≥n v√°lida
                        if details['descripcion'] and len(details['descripcion']) > 15:
                            course = {
                                'titulo': title,
                                'url': course_url,
                                'plataforma': 'Khan Academy',
                                'disponible': 1
                            }
                            course.update(details)
                            courses.append(course)
                            processed += 1
                            logger.info(f"   ‚úÖ Agregado: {len(details['descripcion'])} chars descripci√≥n")
                        else:
                            logger.warning(f"   ‚ö†Ô∏è Descripci√≥n insuficiente, omitiendo")
                            
        except Exception as e:
            logger.error(f"‚ùå Error en Khan Academy: {e}")
        
        logger.info(f"üìä Khan Academy: {len(courses)} cursos procesados con detalles verificados")
        return courses

    # ================== FREECODECAMP SCRAPER (CON VERIFICACI√ìN MEJORADA) ==================
    def search_freecodecamp(self, query):
        """Scraper para freeCodeCamp con verificaci√≥n mejorada"""
        logger.info(f"üíª Buscando en freeCodeCamp: {query}")
        courses = []
        
        try:
            base_courses = [
                {
                    'titulo': 'Responsive Web Design',
                    'url': 'https://www.freecodecamp.org/learn/responsive-web-design/',
                    'keywords': ['web', 'html', 'css', 'design', 'programacion', 'frontend']
                },
                {
                    'titulo': 'JavaScript Algorithms and Data Structures',
                    'url': 'https://www.freecodecamp.org/learn/javascript-algorithms-and-data-structures/',
                    'keywords': ['javascript', 'programacion', 'algoritmos', 'programming', 'js']
                },
                {
                    'titulo': 'Front End Development Libraries',
                    'url': 'https://www.freecodecamp.org/learn/front-end-development-libraries/',
                    'keywords': ['react', 'frontend', 'programacion', 'web', 'libraries']
                },
                {
                    'titulo': 'Data Visualization',
                    'url': 'https://www.freecodecamp.org/learn/data-visualization/',
                    'keywords': ['data', 'visualization', 'datos', 'programacion', 'charts']
                },
                {
                    'titulo': 'APIs and Microservices',
                    'url': 'https://www.freecodecamp.org/learn/apis-and-microservices/',
                    'keywords': ['api', 'backend', 'nodejs', 'programacion', 'microservices']
                },
                {
                    'titulo': 'Scientific Computing with Python',
                    'url': 'https://www.freecodecamp.org/learn/scientific-computing-with-python/',
                    'keywords': ['python', 'programacion', 'ciencia', 'matematicas', 'computing']
                },
                {
                    'titulo': 'Data Analysis with Python',
                    'url': 'https://www.freecodecamp.org/learn/data-analysis-with-python/',
                    'keywords': ['python', 'data', 'analisis', 'datos', 'matematicas', 'analysis']
                },
                {
                    'titulo': 'Machine Learning with Python',
                    'url': 'https://www.freecodecamp.org/learn/machine-learning-with-python/',
                    'keywords': ['python', 'machine learning', 'ai', 'artificial intelligence', 'ml']
                }
            ]
            
            query_lower = query.lower()
            for course_info in base_courses:
                if any(keyword in query_lower for keyword in course_info['keywords']):
                    logger.info(f"   üîç Verificando: {course_info['titulo']}...")
                    
                    # OBTENER DETALLES REALES MEJORADOS
                    time.sleep(random.uniform(1, 3))
                    details = self.get_freecodecamp_details(course_info['url'])
                    
                    # Solo agregar si tenemos descripci√≥n v√°lida
                    if details['descripcion'] and len(details['descripcion']) > 20:
                        course = {
                            'titulo': course_info['titulo'],
                            'url': course_info['url'],
                            'plataforma': 'freeCodeCamp',
                            'disponible': 1
                        }
                        course.update(details)
                        courses.append(course)
                        logger.info(f"   ‚úÖ Agregado: Cert: {'S√≠' if details['certificado'] else 'No'} - {len(details['descripcion'])} chars")
                    else:
                        logger.warning(f"   ‚ö†Ô∏è Descripci√≥n insuficiente para {course_info['titulo']}")
                    
        except Exception as e:
            logger.error(f"‚ùå Error en freeCodeCamp: {e}")
        
        logger.info(f"üìä freeCodeCamp: {len(courses)} cursos procesados con detalles verificados")
        return courses

    # ================== FUNCI√ìN PRINCIPAL MEJORADA ==================
    def search_all_platforms(self, query):
        """Busca en todas las plataformas con verificaci√≥n completa"""
        logger.info(f"üåê Iniciando b√∫squeda multi-plataforma MEJORADA para: '{query}'")
        
        all_courses = []
        
        platforms = [
            ('Coursera', self.search_coursera),
            ('edX', self.search_edx),
            ('Khan Academy', self.search_khan_academy),
            ('freeCodeCamp', self.search_freecodecamp)
        ]
        
        for platform_name, search_function in platforms:
            try:
                logger.info(f"\nüîç Procesando {platform_name}...")
                courses = search_function(query)
                
                # Log detallado de cada curso encontrado
                for course in courses:
                    desc_preview = course.get('descripcion', '')[:60] + "..." if len(course.get('descripcion', '')) > 60 else course.get('descripcion', '')
                    logger.info(f"   ‚úÖ {course['titulo'][:30]}... | {course.get('tipo', 'N/A')} | Cert: {'‚úì' if course.get('certificado', 0) else '‚úó'} | Desc: {len(desc_preview)} chars")
                
                all_courses.extend(courses)
                
                # Pausa m√°s inteligente entre plataformas
                if platform_name != platforms[-1][0]:  # No pausar despu√©s de la √∫ltima plataforma
                    pausa = random.uniform(4, 8)
                    logger.info(f"‚è∏Ô∏è Pausa de {pausa:.1f}s antes de {platforms[platforms.index((platform_name, search_function)) + 1][0]}...")
                    time.sleep(pausa)
                
            except Exception as e:
                logger.error(f"‚ùå Error procesando {platform_name}: {e}")
                continue
        
        # Remover duplicados por URL y validar calidad
        unique_courses = []
        seen_urls = set()
        
        for course in all_courses:
            if (course['url'] not in seen_urls and 
                course.get('descripcion') and 
                len(course.get('descripcion', '')) > 15):  # M√≠nimo 15 caracteres
                unique_courses.append(course)
                seen_urls.add(course['url'])
        
        # Estad√≠sticas finales detalladas
        if unique_courses:
            stats = {
                'total': len(unique_courses),
                'gratis': len([c for c in unique_courses if c.get('tipo') == 'gratis']),
                'pago': len([c for c in unique_courses if c.get('tipo') == 'pago']),
                'freemium': len([c for c in unique_courses if c.get('tipo') == 'freemium']),
                'con_certificado': len([c for c in unique_courses if c.get('certificado') == 1]),
                'sin_certificado': len([c for c in unique_courses if c.get('certificado') == 0]),
                'desc_promedio': sum(len(c.get('descripcion', '')) for c in unique_courses) // len(unique_courses)
            }
            
            logger.info(f"\nüéâ RESULTADOS FINALES PARA '{query}':")
            logger.info(f"   üìä Total cursos √∫nicos: {stats['total']}")
            logger.info(f"   üí∞ Gratis: {stats['gratis']} | üí≥ Pago: {stats['pago']} | üîÑ Freemium: {stats['freemium']}")
            logger.info(f"   üèÜ Con certificado: {stats['con_certificado']} | üìú Sin certificado: {stats['sin_certificado']}")
            logger.info(f"   üìù Descripci√≥n promedio: {stats['desc_promedio']} caracteres")
        
        return unique_courses


def obtener_categorias():
    """Obtiene categor√≠as de la base de datos"""
    conn = get_connection()
    categorias = {}
    if conn:
        try:
            cursor = conn.cursor()
            cursor.execute("SELECT id, nombre FROM categorias")
            for id_, nombre in cursor.fetchall():
                categorias[id_] = nombre.strip()
            cursor.close()
        finally:
            conn.close()
    return categorias

def guardar_cursos(cursos, categoria_id):
    """Guarda cursos en la base de datos con validaci√≥n mejorada"""
    conn = get_connection()
    if not conn:
        logger.error("‚ö†Ô∏è No se pudo conectar a base de datos")
        return 0
    
    cursor = conn.cursor()
    nuevos = 0
    actualizados = 0
    
    for curso in cursos:
        try:
            # Verificar si el curso ya existe
            cursor.execute("SELECT id, descripcion FROM recursos WHERE url = %s", (curso["url"],))
            existing = cursor.fetchone()
            
            if existing is None:
                # Insertar nuevo curso con todos los detalles verificados
                cursor.execute("""
                INSERT INTO recursos
                (titulo, descripcion, url, categoria_id, fecha_publicacion, disponible, tipo, certificado)
                VALUES (%s,%s,%s,%s,%s,%s,%s,%s)
                """, (
                    curso["titulo"],
                    curso.get("descripcion", ""),
                    curso["url"],
                    categoria_id,
                    datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    curso.get("disponible", 1),
                    curso.get("tipo", "gratis"),
                    curso.get("certificado", 0)
                ))
                nuevos += 1
                logger.info(f"   ‚úÖ NUEVO: {curso['titulo'][:45]}... | {curso.get('tipo', 'N/A')} | Cert: {'‚úì' if curso.get('certificado', 0) else '‚úó'} | Desc: {len(curso.get('descripcion', ''))} chars")
            
            else:
                # Actualizar curso existente si tenemos mejor descripci√≥n
                existing_desc = existing[1] or ""
                new_desc = curso.get("descripcion", "")
                
                if len(new_desc) > len(existing_desc):
                    cursor.execute("""
                    UPDATE recursos 
                    SET descripcion = %s, tipo = %s, certificado = %s, fecha_publicacion = %s
                    WHERE url = %s
                    """, (
                        new_desc,
                        curso.get("tipo", "gratis"),
                        curso.get("certificado", 0),
                        datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        curso["url"]
                    ))
                    actualizados += 1
                    logger.info(f"   üîÑ ACTUALIZADO: {curso['titulo'][:40]}... | Mejor descripci√≥n: {len(new_desc)} chars")
                
        except Exception as e:
            logger.error(f"Error guardando/actualizando curso: {e}")
    
    conn.commit()
    cursor.close()
    conn.close()
    
    logger.info(f"üíæ Guardado: {nuevos} nuevos, {actualizados} actualizados")
    return nuevos + actualizados

def main():
    """Funci√≥n principal mejorada"""
    logger.info("üöÄ Iniciando Multi-Platform Course Scraper - VERSI√ìN MEJORADA")
    logger.info("üìö Plataformas: Coursera, edX, Khan Academy, freeCodeCamp")
    logger.info("üîç CON VERIFICACI√ìN REAL Y ROBUSTA DE DETALLES DE CADA CURSO")
    logger.info("‚úÖ Validaci√≥n de: Descripci√≥n, Certificado, Tipo (gratis/pago/freemium)")
    
    categorias = obtener_categorias()
    if not categorias:
        logger.error("‚ö†Ô∏è No hay categor√≠as en la BD.")
        return
    
    scraper = MultiPlatformScraper()
    total_procesados = 0
    estadisticas_globales = {
        'gratis': 0,
        'pago': 0,
        'freemium': 0,
        'con_certificado': 0,
        'sin_certificado': 0,
        'total_caracteres_desc': 0
    }
    
    for cat_id, nombre in categorias.items():
        logger.info(f"\nüéØ Procesando categor√≠a: '{nombre}' (ID: {cat_id})")
        
        try:
            cursos = scraper.search_all_platforms(nombre)
            
            if cursos:
                # Actualizar estad√≠sticas globales
                for curso in cursos:
                    tipo = curso.get('tipo', 'gratis')
                    if tipo == 'gratis':
                        estadisticas_globales['gratis'] += 1
                    elif tipo == 'pago':
                        estadisticas_globales['pago'] += 1
                    elif tipo == 'freemium':
                        estadisticas_globales['freemium'] += 1
                    
                    if curso.get('certificado', 0) == 1:
                        estadisticas_globales['con_certificado'] += 1
                    else:
                        estadisticas_globales['sin_certificado'] += 1
                    
                    estadisticas_globales['total_caracteres_desc'] += len(curso.get('descripcion', ''))
                
                # Guardar en base de datos
                procesados = guardar_cursos(cursos, cat_id)
                total_procesados += procesados
                
                logger.info(f"‚úÖ Categor√≠a '{nombre}' completada: {procesados} cursos procesados de {len(cursos)} encontrados")
            else:
                logger.warning(f"‚ùå No se encontraron cursos v√°lidos para: '{nombre}'")
            
            # Pausa inteligente entre categor√≠as
            if list(categorias.keys()).index(cat_id) < len(categorias) - 1:
                pausa = random.uniform(10, 18)
                logger.info(f"‚è∏Ô∏è Pausa de {pausa:.1f}s antes de siguiente categor√≠a...")
                time.sleep(pausa)
                
        except Exception as e:
            logger.error(f"‚ùå Error procesando categor√≠a '{nombre}': {e}")
            continue
    
    # Resumen final detallado
    logger.info(f"\nüéâ SCRAPING COMPLETADO CON √âXITO!")
    logger.info(f"üìà Total cursos procesados: {total_procesados}")
    logger.info(f"üåê Plataformas con verificaci√≥n completa: Coursera, edX, Khan Academy, freeCodeCamp")
    logger.info(f"\nüìä ESTAD√çSTICAS GLOBALES:")
    logger.info(f"   üí∞ Cursos gratuitos: {estadisticas_globales['gratis']}")
    logger.info(f"   üí≥ Cursos de pago: {estadisticas_globales['pago']}")
    logger.info(f"   üîÑ Cursos freemium: {estadisticas_globales['freemium']}")
    logger.info(f"   üèÜ Con certificado: {estadisticas_globales['con_certificado']}")
    logger.info(f"   üìú Sin certificado: {estadisticas_globales['sin_certificado']}")
    
    if total_procesados > 0:
        promedio_desc = estadisticas_globales['total_caracteres_desc'] // total_procesados
        logger.info(f"   üìù Descripci√≥n promedio: {promedio_desc} caracteres")
    
    logger.info(f"\n‚úÖ TODOS LOS CURSOS GUARDADOS CON:")
    logger.info(f"   ‚Ä¢ Descripci√≥n real verificada")
    logger.info(f"   ‚Ä¢ Tipo correcto (gratis/pago/freemium)")
    logger.info(f"   ‚Ä¢ Estado de certificado verificado")

if __name__ == "__main__":
    main()"""